{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkdKjVqqV-Xt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU1otZEWV-Xv"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('spam.csv', encoding='ISO-8859-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgcAAU7lV-Xv",
        "outputId": "4838c20b-a72b-4656-b619-9ffd51e98d6d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1                                                 v2 Unnamed: 2  \\\n",
              "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
              "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
              "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
              "\n",
              "  Unnamed: 3 Unnamed: 4  \n",
              "0        NaN        NaN  \n",
              "1        NaN        NaN  \n",
              "2        NaN        NaN  \n",
              "3        NaN        NaN  \n",
              "4        NaN        NaN  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqLZmmukV-Xw"
      },
      "outputs": [],
      "source": [
        "dataset.rename(columns={'v1':'Target','v2':'mailText'},inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNSCkI2WV-Xw",
        "outputId": "8bd77c58-694b-4644-87aa-7621b992aad8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Target           2\n",
              "mailText      5169\n",
              "Unnamed: 2      43\n",
              "Unnamed: 3      10\n",
              "Unnamed: 4       5\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKvOCqrWV-Xw"
      },
      "outputs": [],
      "source": [
        "dataset['mailText'] = dataset['mailText'].fillna('') + dataset['Unnamed: 2'].fillna('') + dataset['Unnamed: 3'].fillna('') + dataset['Unnamed: 4'].fillna('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rjlRXNEV-Xw",
        "outputId": "6a638d2d-22a1-4bc9-8e18-ac0554fc53e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Target           0\n",
              "mailText         0\n",
              "Unnamed: 2    5522\n",
              "Unnamed: 3    5560\n",
              "Unnamed: 4    5566\n",
              "dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bisWyV9xV-Xx",
        "outputId": "c04a612c-3ec2-4091-9368-a534bd75ec13"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>mailText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Target                                           mailText\n",
              "0    ham  Go until jurong point, crazy.. Available only ...\n",
              "1    ham                      Ok lar... Joking wif u oni...\n",
              "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3    ham  U dun say so early hor... U c already then say...\n",
              "4    ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1,inplace=True)\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKmmgETlV-Xx",
        "outputId": "0764fb12-c226-43b4-df65-bb6e4b301f7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count of 'spam': 747\n",
            "Count of 'not spam': 4825\n"
          ]
        }
      ],
      "source": [
        "count_spam = dataset['Target'].value_counts().get('spam', 0)\n",
        "count_not_spam = dataset['Target'].value_counts().get('ham', 0)\n",
        "\n",
        "print(\"Count of 'spam':\", count_spam)\n",
        "print(\"Count of 'not spam':\", count_not_spam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jIZbuKhV-Xx",
        "outputId": "fdc44866-c021-42ac-aec9-71cdcd5b82ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>mailText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Target                                           mailText\n",
              "0    ham  go until jurong point, crazy.. available only ...\n",
              "1    ham                      ok lar... joking wif u oni...\n",
              "2   spam  free entry in 2 a wkly comp to win fa cup fina...\n",
              "3    ham  u dun say so early hor... u c already then say...\n",
              "4    ham  nah i don't think he goes to usf, he lives aro..."
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['mailText'] = dataset['mailText'].str.lower()\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tX2K2ZxnV-Xy"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def tokenize_text(text) :\n",
        "    return word_tokenize(text)\n",
        "\n",
        "dataset['Tokenize Text'] = dataset['mailText'].apply(tokenize_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBX22JmIV-Xy",
        "outputId": "0d5b2a86-4072-4a2d-c2cf-6df13489fa09"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>mailText</th>\n",
              "      <th>Tokenize Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "      <td>[go, until, jurong, point, ,, crazy, .., avail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "      <td>[ok, lar, ..., joking, wif, u, oni, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "      <td>[u, dun, say, so, early, hor, ..., u, c, alrea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "      <td>[nah, i, do, n't, think, he, goes, to, usf, ,,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Target                                           mailText  \\\n",
              "0    ham  go until jurong point, crazy.. available only ...   \n",
              "1    ham                      ok lar... joking wif u oni...   \n",
              "2   spam  free entry in 2 a wkly comp to win fa cup fina...   \n",
              "3    ham  u dun say so early hor... u c already then say...   \n",
              "4    ham  nah i don't think he goes to usf, he lives aro...   \n",
              "\n",
              "                                       Tokenize Text  \n",
              "0  [go, until, jurong, point, ,, crazy, .., avail...  \n",
              "1           [ok, lar, ..., joking, wif, u, oni, ...]  \n",
              "2  [free, entry, in, 2, a, wkly, comp, to, win, f...  \n",
              "3  [u, dun, say, so, early, hor, ..., u, c, alrea...  \n",
              "4  [nah, i, do, n't, think, he, goes, to, usf, ,,...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfecFg4_V-Xy"
      },
      "outputs": [],
      "source": [
        "def remove_numbers(tokens):\n",
        "    return [ token for token in tokens if not token.isdigit()]\n",
        "\n",
        "\n",
        "dataset['Tokenize Text'] = dataset['Tokenize Text'].apply(remove_numbers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QQjpt2jV-Xy"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuations(tokens):\n",
        "    return [ token for token in tokens if not token in string.punctuation ]\n",
        "\n",
        "dataset['Tokenize Text'] = dataset['Tokenize Text'].apply(remove_punctuations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MF_RQRoYV-Xy"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    stopwords_list = stopwords.words('english')\n",
        "    return [ token for token in tokens if token not in stopwords_list]\n",
        "\n",
        "dataset['Tokenize Text'] = dataset['Tokenize Text'].apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW0NcNDFV-Xy"
      },
      "source": [
        "4. Stemming\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrleRTywV-Xy"
      },
      "outputs": [],
      "source": [
        "from nltk import SnowballStemmer\n",
        "\n",
        "lang = \"english\"\n",
        "stemmer = SnowballStemmer(lang)\n",
        "def adding_Stemming(tokens):\n",
        "    return [ stemmer.stem(token) for token in tokens ]\n",
        "\n",
        "dataset['Tokenize Text'] = dataset['Tokenize Text'].apply(adding_Stemming)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "darEyXf6V-Xy",
        "outputId": "78a3b6de-d2cd-4280-cc6c-ff2eda0cc459"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>mailText</th>\n",
              "      <th>Tokenize Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "      <td>[go, jurong, point, crazi, .., avail, bugi, n,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "      <td>[free, entri, wkli, comp, win, fa, cup, final,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "      <td>[u, dun, say, earli, hor, ..., u, c, alreadi, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "      <td>[nah, n't, think, goe, usf, live, around, though]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Target                                           mailText  \\\n",
              "0    ham  go until jurong point, crazy.. available only ...   \n",
              "1    ham                      ok lar... joking wif u oni...   \n",
              "2   spam  free entry in 2 a wkly comp to win fa cup fina...   \n",
              "3    ham  u dun say so early hor... u c already then say...   \n",
              "4    ham  nah i don't think he goes to usf, he lives aro...   \n",
              "\n",
              "                                       Tokenize Text  \n",
              "0  [go, jurong, point, crazi, .., avail, bugi, n,...  \n",
              "1             [ok, lar, ..., joke, wif, u, oni, ...]  \n",
              "2  [free, entri, wkli, comp, win, fa, cup, final,...  \n",
              "3  [u, dun, say, earli, hor, ..., u, c, alreadi, ...  \n",
              "4  [nah, n't, think, goe, usf, live, around, though]  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-bLt-wcV-Xy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cet9wBuFV-Xy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIo_El4bV-Xz",
        "outputId": "5f8a9340-bcd5-485e-e847-43ea8815b784"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>mailText</th>\n",
              "      <th>Tokenize Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "      <td>[go, jurong, point, crazi, .., avail, bugi, n,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "      <td>[free, entri, wkli, comp, win, fa, cup, final,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "      <td>[u, dun, say, earli, hor, ..., u, c, alreadi, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "      <td>[nah, n't, think, goe, usf, live, around, though]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Target                                           mailText  \\\n",
              "0    ham  go until jurong point, crazy.. available only ...   \n",
              "1    ham                      ok lar... joking wif u oni...   \n",
              "2   spam  free entry in 2 a wkly comp to win fa cup fina...   \n",
              "3    ham  u dun say so early hor... u c already then say...   \n",
              "4    ham  nah i don't think he goes to usf, he lives aro...   \n",
              "\n",
              "                                       Tokenize Text  \n",
              "0  [go, jurong, point, crazi, .., avail, bugi, n,...  \n",
              "1             [ok, lar, ..., joke, wif, u, oni, ...]  \n",
              "2  [free, entri, wkli, comp, win, fa, cup, final,...  \n",
              "3  [u, dun, say, earli, hor, ..., u, c, alreadi, ...  \n",
              "4  [nah, n't, think, goe, usf, live, around, though]  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d2set = dataset\n",
        "d2set.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjaXmQc0V-Xz"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import Tfid3setVectorizer\n",
        "\n",
        "tfid3set_vectorizer = Tfid3setVectorizer()\n",
        "\n",
        "tfid3set_matrix = tfid3set_vectorizer.fit_transform([\" \".join(doc) for doc in d2set['Tokenize Text']])\n",
        "\n",
        "tfid3set_d3set = pd.DataFrame(tfid3set_matrix.toarray(), columns=tfid3set_vectorizer.get_feature_names_out())\n",
        "\n",
        "d2set = pd.concat([dataset, tfid3set_d3set], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbg3eOHoV-Xz",
        "outputId": "74d1f716-bfa8-4ce4-951f-5ed6eb3a2249"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>mailText</th>\n",
              "      <th>Tokenize Text</th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>000pes</th>\n",
              "      <th>02</th>\n",
              "      <th>0207</th>\n",
              "      <th>02072069400</th>\n",
              "      <th>03</th>\n",
              "      <th>...</th>\n",
              "      <th>ó_</th>\n",
              "      <th>û_</th>\n",
              "      <th>û_thank</th>\n",
              "      <th>ûªm</th>\n",
              "      <th>ûªt</th>\n",
              "      <th>ûªv</th>\n",
              "      <th>ûï</th>\n",
              "      <th>ûïharri</th>\n",
              "      <th>ûò</th>\n",
              "      <th>ûówel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "      <td>[go, jurong, point, crazi, .., avail, bugi, n,...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "      <td>[free, entri, wkli, comp, win, fa, cup, final,...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "      <td>[u, dun, say, earli, hor, ..., u, c, alreadi, ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "      <td>[nah, n't, think, goe, usf, live, around, though]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 7073 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  Target                                           mailText  \\\n",
              "0    ham  go until jurong point, crazy.. available only ...   \n",
              "1    ham                      ok lar... joking wif u oni...   \n",
              "2   spam  free entry in 2 a wkly comp to win fa cup fina...   \n",
              "3    ham  u dun say so early hor... u c already then say...   \n",
              "4    ham  nah i don't think he goes to usf, he lives aro...   \n",
              "\n",
              "                                       Tokenize Text   00  000  000pes   02  \\\n",
              "0  [go, jurong, point, crazi, .., avail, bugi, n,...  0.0  0.0     0.0  0.0   \n",
              "1             [ok, lar, ..., joke, wif, u, oni, ...]  0.0  0.0     0.0  0.0   \n",
              "2  [free, entri, wkli, comp, win, fa, cup, final,...  0.0  0.0     0.0  0.0   \n",
              "3  [u, dun, say, earli, hor, ..., u, c, alreadi, ...  0.0  0.0     0.0  0.0   \n",
              "4  [nah, n't, think, goe, usf, live, around, though]  0.0  0.0     0.0  0.0   \n",
              "\n",
              "   0207  02072069400   03  ...   ó_   û_  û_thank  ûªm  ûªt  ûªv   ûï  \\\n",
              "0   0.0          0.0  0.0  ...  0.0  0.0      0.0  0.0  0.0  0.0  0.0   \n",
              "1   0.0          0.0  0.0  ...  0.0  0.0      0.0  0.0  0.0  0.0  0.0   \n",
              "2   0.0          0.0  0.0  ...  0.0  0.0      0.0  0.0  0.0  0.0  0.0   \n",
              "3   0.0          0.0  0.0  ...  0.0  0.0      0.0  0.0  0.0  0.0  0.0   \n",
              "4   0.0          0.0  0.0  ...  0.0  0.0      0.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "   ûïharri   ûò  ûówel  \n",
              "0      0.0  0.0    0.0  \n",
              "1      0.0  0.0    0.0  \n",
              "2      0.0  0.0    0.0  \n",
              "3      0.0  0.0    0.0  \n",
              "4      0.0  0.0    0.0  \n",
              "\n",
              "[5 rows x 7073 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d2set.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OL6hFyCOV-Xz"
      },
      "outputs": [],
      "source": [
        "d2set['Target'] = d2set['Target'].apply(lambda x : 1 if x == \"ham\" else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tElhULQDV-Xz",
        "outputId": "ddf7782b-56dd-408f-9a6c-deaa085297d5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>mailText</th>\n",
              "      <th>Tokenize Text</th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>000pes</th>\n",
              "      <th>02</th>\n",
              "      <th>0207</th>\n",
              "      <th>02072069400</th>\n",
              "      <th>03</th>\n",
              "      <th>...</th>\n",
              "      <th>ó_</th>\n",
              "      <th>û_</th>\n",
              "      <th>û_thank</th>\n",
              "      <th>ûªm</th>\n",
              "      <th>ûªt</th>\n",
              "      <th>ûªv</th>\n",
              "      <th>ûï</th>\n",
              "      <th>ûïharri</th>\n",
              "      <th>ûò</th>\n",
              "      <th>ûówel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "      <td>[go, jurong, point, crazi, .., avail, bugi, n,...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "      <td>[free, entri, wkli, comp, win, fa, cup, final,...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "      <td>[u, dun, say, earli, hor, ..., u, c, alreadi, ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "      <td>[nah, n't, think, goe, usf, live, around, though]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 7073 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Target                                           mailText  \\\n",
              "0       1  go until jurong point, crazy.. available only ...   \n",
              "1       1                      ok lar... joking wif u oni...   \n",
              "2       0  free entry in 2 a wkly comp to win fa cup fina...   \n",
              "3       1  u dun say so early hor... u c already then say...   \n",
              "4       1  nah i don't think he goes to usf, he lives aro...   \n",
              "\n",
              "                                       Tokenize Text   00  000  000pes   02  \\\n",
              "0  [go, jurong, point, crazi, .., avail, bugi, n,...  0.0  0.0     0.0  0.0   \n",
              "1             [ok, lar, ..., joke, wif, u, oni, ...]  0.0  0.0     0.0  0.0   \n",
              "2  [free, entri, wkli, comp, win, fa, cup, final,...  0.0  0.0     0.0  0.0   \n",
              "3  [u, dun, say, earli, hor, ..., u, c, alreadi, ...  0.0  0.0     0.0  0.0   \n",
              "4  [nah, n't, think, goe, usf, live, around, though]  0.0  0.0     0.0  0.0   \n",
              "\n",
              "   0207  02072069400   03  ...   ó_   û_  û_thank  ûªm  ûªt  ûªv   ûï  \\\n",
              "0   0.0          0.0  0.0  ...  0.0  0.0      0.0  0.0  0.0  0.0  0.0   \n",
              "1   0.0          0.0  0.0  ...  0.0  0.0      0.0  0.0  0.0  0.0  0.0   \n",
              "2   0.0          0.0  0.0  ...  0.0  0.0      0.0  0.0  0.0  0.0  0.0   \n",
              "3   0.0          0.0  0.0  ...  0.0  0.0      0.0  0.0  0.0  0.0  0.0   \n",
              "4   0.0          0.0  0.0  ...  0.0  0.0      0.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "   ûïharri   ûò  ûówel  \n",
              "0      0.0  0.0    0.0  \n",
              "1      0.0  0.0    0.0  \n",
              "2      0.0  0.0    0.0  \n",
              "3      0.0  0.0    0.0  \n",
              "4      0.0  0.0    0.0  \n",
              "\n",
              "[5 rows x 7073 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d2set.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LURyuegiV-Xz"
      },
      "outputs": [],
      "source": [
        "X = d2set.drop(['Target','mailText','Tokenize Text'],axis=1)\n",
        "Y = d2set['Target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0QsXPYBV-Xz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuqJzcIlV-X0",
        "outputId": "4bdc42c3-cd73-4a7b-b487-d95af9d9a047"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes Classifier \n",
            "--------------------------------------------------------------\n",
            "Accuracy Score :  0.8708520179372198\n",
            "Calssification Report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.51      0.65       264\n",
            "           1       0.87      0.98      0.92       851\n",
            "\n",
            "    accuracy                           0.87      1115\n",
            "   macro avg       0.88      0.75      0.79      1115\n",
            "weighted avg       0.87      0.87      0.86      1115\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "tf_naive = GaussianNB()\n",
        "tf_naive.fit(x_train,y_train)\n",
        "\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "pred_naive = tf_naive.predict(x_test)\n",
        "print(\"Naive Bayes Classifier \")\n",
        "print(\"--------------------------------------------------------------\")\n",
        "print(\"Accuracy Score : \",accuracy_score(pred_naive,y_test))\n",
        "print(\"Calssification Report : \\n\",classification_report(pred_naive,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPG6UwqkV-X0",
        "outputId": "9b91e95d-5086-4b51-f552-110762b67f86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression \n",
            "--------------------------------------------------------------\n",
            "Accuracy Score :  0.9497757847533632\n",
            "Calssification Report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.96      0.78       102\n",
            "           1       1.00      0.95      0.97      1013\n",
            "\n",
            "    accuracy                           0.95      1115\n",
            "   macro avg       0.82      0.95      0.87      1115\n",
            "weighted avg       0.96      0.95      0.95      1115\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "tf_log = LogisticRegression()\n",
        "tf_log.fit(x_train,y_train)\n",
        "\n",
        "pred_log = tf_log.predict(x_test)\n",
        "print(\"Logistic Regression \")\n",
        "print(\"--------------------------------------------------------------\")\n",
        "print(\"Accuracy Score : \",accuracy_score(pred_log,y_test))\n",
        "print(\"Calssification Report : \\n\",classification_report(pred_log,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JU3TNZOBV-X0",
        "outputId": "4288cc61-d586-4cfc-fc85-406529f07d63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Support Vector Machine \n",
            "--------------------------------------------------------------\n",
            "Accuracy Score :  0.9802690582959641\n",
            "Calssification Report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.98      0.92       134\n",
            "           1       1.00      0.98      0.99       981\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.94      0.98      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "tf_svm = SVC(kernel='linear',C=1,random_state=42)\n",
        "tf_svm.fit(x_train,y_train)\n",
        "\n",
        "pred_svm = tf_svm.predict(x_test)\n",
        "print(\"Support Vector Machine \")\n",
        "print(\"--------------------------------------------------------------\")\n",
        "print(\"Accuracy Score : \",accuracy_score(pred_svm,y_test))\n",
        "print(\"Calssification Report : \\n\",classification_report(pred_svm,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0_r7WrOV-X0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioXPrzMvV-X1",
        "outputId": "7095ee09-ad8a-4689-b9c0-e2a1f885e7f6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>mailText</th>\n",
              "      <th>Tokenize Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "      <td>[go, jurong, point, crazi, .., avail, bugi, n,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "      <td>[free, entri, wkli, comp, win, fa, cup, final,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "      <td>[u, dun, say, earli, hor, ..., u, c, alreadi, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "      <td>[nah, n't, think, goe, usf, live, around, though]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Target                                           mailText  \\\n",
              "0    ham  go until jurong point, crazy.. available only ...   \n",
              "1    ham                      ok lar... joking wif u oni...   \n",
              "2   spam  free entry in 2 a wkly comp to win fa cup fina...   \n",
              "3    ham  u dun say so early hor... u c already then say...   \n",
              "4    ham  nah i don't think he goes to usf, he lives aro...   \n",
              "\n",
              "                                       Tokenize Text  \n",
              "0  [go, jurong, point, crazi, .., avail, bugi, n,...  \n",
              "1             [ok, lar, ..., joke, wif, u, oni, ...]  \n",
              "2  [free, entri, wkli, comp, win, fa, cup, final,...  \n",
              "3  [u, dun, say, earli, hor, ..., u, c, alreadi, ...  \n",
              "4  [nah, n't, think, goe, usf, live, around, though]  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d3set = dataset\n",
        "d3set.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpDoqOHdV-X1"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "tokenized_text = d3set['Tokenize Text']\n",
        "model = Word2Vec(sentences=tokenized_text, vector_size=100, window=5, min_count=1, sg=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imubzdf7V-X1"
      },
      "outputs": [],
      "source": [
        "def document_vector(tokens, model, num_features):\n",
        "    feature_vector = np.zeros((num_features,), dtype=\"float32\")\n",
        "    num_words = 0\n",
        "\n",
        "    for word in tokens:\n",
        "        if word in model.wv:\n",
        "            num_words += 1\n",
        "            feature_vector = np.add(feature_vector, model.wv[word])\n",
        "\n",
        "    if num_words > 0:\n",
        "        feature_vector = np.divide(feature_vector, num_words)\n",
        "    return feature_vector\n",
        "num_features = 100\n",
        "document_vectors = []\n",
        "for tokens in tokenized_text:\n",
        "    vector = document_vector(tokens, model, num_features)\n",
        "    document_vectors.append(vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMLC7_TEV-X1"
      },
      "outputs": [],
      "source": [
        "X = pd.DataFrame(document_vectors)\n",
        "Y = d3set['Target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kwp8r4IqV-X1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTboc2mPV-X1",
        "outputId": "92ac5e10-b520-4bcc-b697-c8f404012f67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes Classifier \n",
            "--------------------------------------------------------------\n",
            "Accuracy Score :  0.5004484304932736\n",
            "Calssification Report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.45      0.94      0.61       460\n",
            "        spam       0.83      0.19      0.31       655\n",
            "\n",
            "    accuracy                           0.50      1115\n",
            "   macro avg       0.64      0.57      0.46      1115\n",
            "weighted avg       0.67      0.50      0.43      1115\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "w2v_naive = GaussianNB()\n",
        "w2v_naive.fit(x_train,y_train)\n",
        "\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "pred_naive = w2v_naive.predict(x_test)\n",
        "print(\"Naive Bayes Classifier \")\n",
        "print(\"--------------------------------------------------------------\")\n",
        "print(\"Accuracy Score : \",accuracy_score(pred_naive,y_test))\n",
        "print(\"Calssification Report : \\n\",classification_report(pred_naive,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJ7YkRM3V-X2",
        "outputId": "5ede04fb-8496-4a95-c7d9-2c8236116d8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression \n",
            "--------------------------------------------------------------\n",
            "Accuracy Score :  0.8654708520179372\n",
            "Calssification Report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         ham       1.00      0.87      0.93      1115\n",
            "        spam       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.87      1115\n",
            "   macro avg       0.50      0.43      0.46      1115\n",
            "weighted avg       1.00      0.87      0.93      1115\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "w2v_log = LogisticRegression()\n",
        "w2v_log.fit(x_train,y_train)\n",
        "\n",
        "pred_log = w2v_log.predict(x_test)\n",
        "print(\"Logistic Regression \")\n",
        "print(\"--------------------------------------------------------------\")\n",
        "print(\"Accuracy Score : \",accuracy_score(pred_log,y_test))\n",
        "print(\"Calssification Report : \\n\",classification_report(pred_log,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSZ8lxe6V-X2",
        "outputId": "c8e97644-e905-45b0-90d9-e9f713b13980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Support Vector Machine \n",
            "--------------------------------------------------------------\n",
            "Accuracy Score :  0.8654708520179372\n",
            "Calssification Report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         ham       1.00      0.87      0.93      1115\n",
            "        spam       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.87      1115\n",
            "   macro avg       0.50      0.43      0.46      1115\n",
            "weighted avg       1.00      0.87      0.93      1115\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "w2v_svm = SVC(kernel='linear',C=1,random_state=42)\n",
        "w2v_svm.fit(x_train,y_train)\n",
        "\n",
        "pred_svm = w2v_svm.predict(x_test)\n",
        "print(\"Support Vector Machine \")\n",
        "print(\"--------------------------------------------------------------\")\n",
        "print(\"Accuracy Score : \",accuracy_score(pred_svm,y_test))\n",
        "print(\"Calssification Report : \\n\",classification_report(pred_svm,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tMQa4lkV-X2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLevFErEV-X2",
        "outputId": "3a2646b6-2215-44b4-ca29-1f54741ec554"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>mailText</th>\n",
              "      <th>Tokenize Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "      <td>[go, jurong, point, crazi, .., avail, bugi, n,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "      <td>[free, entri, wkli, comp, win, fa, cup, final,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "      <td>[u, dun, say, earli, hor, ..., u, c, alreadi, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "      <td>[nah, n't, think, goe, usf, live, around, though]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Target                                           mailText  \\\n",
              "0    ham  go until jurong point, crazy.. available only ...   \n",
              "1    ham                      ok lar... joking wif u oni...   \n",
              "2   spam  free entry in 2 a wkly comp to win fa cup fina...   \n",
              "3    ham  u dun say so early hor... u c already then say...   \n",
              "4    ham  nah i don't think he goes to usf, he lives aro...   \n",
              "\n",
              "                                       Tokenize Text  \n",
              "0  [go, jurong, point, crazi, .., avail, bugi, n,...  \n",
              "1             [ok, lar, ..., joke, wif, u, oni, ...]  \n",
              "2  [free, entri, wkli, comp, win, fa, cup, final,...  \n",
              "3  [u, dun, say, earli, hor, ..., u, c, alreadi, ...  \n",
              "4  [nah, n't, think, goe, usf, live, around, though]  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d3set.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_XFz7BbV-X2"
      },
      "outputs": [],
      "source": [
        "def load_glove_embeddings(file_path):\n",
        "    embeddings_index = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = vector\n",
        "    return embeddings_index\n",
        "\n",
        "# Specify the path to your GloVe file\n",
        "glove_file = './glove.42B.300d.txt'\n",
        "glove_embeddings = load_glove_embeddings(glove_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPBbIyJhV-X3"
      },
      "outputs": [],
      "source": [
        "def get_word_vector(token, embeddings_index):\n",
        "    return embeddings_index.get(token, np.zeros(300))\n",
        "\n",
        "d3set['GloVe Embeddings'] = d3set['Tokenize Text'].apply(lambda tokens: [get_word_vector(token, glove_embeddings) for token in tokens])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_85woM5V-X3",
        "outputId": "7f4e1aa8-524b-4738-b5b9-6e9061ac5794"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>mailText</th>\n",
              "      <th>Tokenize Text</th>\n",
              "      <th>GloVe Embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "      <td>[go, jurong, point, crazi, .., avail, bugi, n,...</td>\n",
              "      <td>[[0.094418, 0.26803, -0.18872, -0.34682, 0.173...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
              "      <td>[[0.05973, 0.11751, -0.19544, -0.2859, 0.34065...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "      <td>[free, entri, wkli, comp, win, fa, cup, final,...</td>\n",
              "      <td>[[-0.61984, -0.31242, 0.39918, 0.48442, 0.1743...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "      <td>[u, dun, say, earli, hor, ..., u, c, alreadi, ...</td>\n",
              "      <td>[[-0.078214, 0.95937, 0.12532, 0.52195, 0.0887...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "      <td>[nah, n't, think, goe, usf, live, around, though]</td>\n",
              "      <td>[[0.28848, 0.1572, 0.49064, -0.057261, -0.5658...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Target                                           mailText  \\\n",
              "0    ham  go until jurong point, crazy.. available only ...   \n",
              "1    ham                      ok lar... joking wif u oni...   \n",
              "2   spam  free entry in 2 a wkly comp to win fa cup fina...   \n",
              "3    ham  u dun say so early hor... u c already then say...   \n",
              "4    ham  nah i don't think he goes to usf, he lives aro...   \n",
              "\n",
              "                                       Tokenize Text  \\\n",
              "0  [go, jurong, point, crazi, .., avail, bugi, n,...   \n",
              "1             [ok, lar, ..., joke, wif, u, oni, ...]   \n",
              "2  [free, entri, wkli, comp, win, fa, cup, final,...   \n",
              "3  [u, dun, say, earli, hor, ..., u, c, alreadi, ...   \n",
              "4  [nah, n't, think, goe, usf, live, around, though]   \n",
              "\n",
              "                                    GloVe Embeddings  \n",
              "0  [[0.094418, 0.26803, -0.18872, -0.34682, 0.173...  \n",
              "1  [[0.05973, 0.11751, -0.19544, -0.2859, 0.34065...  \n",
              "2  [[-0.61984, -0.31242, 0.39918, 0.48442, 0.1743...  \n",
              "3  [[-0.078214, 0.95937, 0.12532, 0.52195, 0.0887...  \n",
              "4  [[0.28848, 0.1572, 0.49064, -0.057261, -0.5658...  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d3set.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zOkt-F2V-X3",
        "outputId": "fc7bd205-f681-4a38-b456-8f996fb78b4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Target              object\n",
              "mailText            object\n",
              "Tokenize Text       object\n",
              "GloVe Embeddings    object\n",
              "dtype: object"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d3set.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ia7K-w9FV-X3"
      },
      "outputs": [],
      "source": [
        "requriedData = d3set['GloVe Embeddings']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBcZeOjZV-X3",
        "outputId": "3331e751-bda3-4912-b682-85374aa3adb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       [[0.094418, 0.26803, -0.18872, -0.34682, 0.173...\n",
              "1       [[0.05973, 0.11751, -0.19544, -0.2859, 0.34065...\n",
              "2       [[-0.61984, -0.31242, 0.39918, 0.48442, 0.1743...\n",
              "3       [[-0.078214, 0.95937, 0.12532, 0.52195, 0.0887...\n",
              "4       [[0.28848, 0.1572, 0.49064, -0.057261, -0.5658...\n",
              "                              ...                        \n",
              "5567    [[0.10397, -0.20526, -0.29512, 0.016276, 0.007...\n",
              "5568    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
              "5569    [[-0.39909, -0.38653, 0.082255, 0.10243, -0.52...\n",
              "5570    [[-0.46733, 0.5856, 0.057228, -0.2123, -0.0979...\n",
              "5571    [[-0.2477, 0.14809, 0.047774, -0.50507, 0.1089...\n",
              "Name: GloVe Embeddings, Length: 5572, dtype: object"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "requriedData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmQ80p5CV-X3"
      },
      "outputs": [],
      "source": [
        "def extract_embeddings(embedding_list):\n",
        "    token_list = [f\"Token_{i}\" for i in range(len(embedding_list))]\n",
        "    data = []\n",
        "\n",
        "    for token, embedding in zip(token_list, embedding_list):\n",
        "        embedding_str = ' '.join(map(str, embedding))\n",
        "        data.append(f\"{token} {embedding_str}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "# Apply the function to the 'GloVe Embeddings' column\n",
        "impData = d3set['GloVe Embeddings'].apply(extract_embeddings)\n",
        "\n",
        "requriedData = pd.DataFrame(impData)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TvpJ8m7V-X3",
        "outputId": "598356c6-f00e-4623-9604-0e1f0bc5901b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GloVe Embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Token_0 0.094418 0.26803 -0.18872 -0.34682 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Token_0 0.05973 0.11751 -0.19544 -0.2859 0.34...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Token_0 -0.61984 -0.31242 0.39918 0.48442 0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Token_0 -0.078214 0.95937 0.12532 0.52195 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Token_0 0.28848 0.1572 0.49064 -0.057261 -0.5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>[Token_0 0.10397 -0.20526 -0.29512 0.016276 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>[Token_0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>[Token_0 -0.39909 -0.38653 0.082255 0.10243 -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>[Token_0 -0.46733 0.5856 0.057228 -0.2123 -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>[Token_0 -0.2477 0.14809 0.047774 -0.50507 0.1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       GloVe Embeddings\n",
              "0     [Token_0 0.094418 0.26803 -0.18872 -0.34682 0....\n",
              "1     [Token_0 0.05973 0.11751 -0.19544 -0.2859 0.34...\n",
              "2     [Token_0 -0.61984 -0.31242 0.39918 0.48442 0.1...\n",
              "3     [Token_0 -0.078214 0.95937 0.12532 0.52195 0.0...\n",
              "4     [Token_0 0.28848 0.1572 0.49064 -0.057261 -0.5...\n",
              "...                                                 ...\n",
              "5567  [Token_0 0.10397 -0.20526 -0.29512 0.016276 0....\n",
              "5568  [Token_0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...\n",
              "5569  [Token_0 -0.39909 -0.38653 0.082255 0.10243 -0...\n",
              "5570  [Token_0 -0.46733 0.5856 0.057228 -0.2123 -0.0...\n",
              "5571  [Token_0 -0.2477 0.14809 0.047774 -0.50507 0.1...\n",
              "\n",
              "[5572 rows x 1 columns]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "requriedData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJhrxQ3EV-X3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}